[
  {
    "objectID": "modules.html",
    "href": "modules.html",
    "title": "Module Setup and Submission",
    "section": "",
    "text": "We’re using Git and GitHub for setting up and submitting modules. Git is a version control system for tracking changes you make to files. GitHub is a hosting service for distributing Git repositories. These tools are essential for collaborative coding projects and it’s important to your development as a data scientist that you learn how to use them.\nThat said, Git and GitHub have a difficult learning curve. In this course, we’re going to limit ourselves to using some basic features. In future courses or when you’re doing research in a lab, you’ll have opportunities to learn more advanced Git and GitHub workflows. For more information about how data scientists use Git and GitHub, I recommend reading Bryan (2018).\nIn brief, module setup has two steps and submission has three.\n\nCreate your own remote repo on GitHub from the module template repo.\nCreate your local repo by cloning your remote to your computer.\n\nNow your computer is set up for the module. Complete the activity according to the instructions on the course website. When you’re done, proceed to the following steps.\n\nCommit your changes in the local repo.\nPush your local commit to the remote repo.\nOpen an Issue on GitHub and tag the instructors.\n\n\n  \n  \n\n\n\n\n\n\n\nImportant\n\n\n\nThere’s a decent chance these instructions feel overwhelming. It’s true, there’s a lot to learn even to set up and submit your modules - certainly trickier than uploading a PDF to Canvas. I encourage you to stick with it! After you set up and submit a couple modules you’ll feel a lot more confident, and by the end of the quarter you’ll have gained valuable experience with an important data science tool."
  },
  {
    "objectID": "modules.html#overview",
    "href": "modules.html#overview",
    "title": "Module Setup and Submission",
    "section": "",
    "text": "We’re using Git and GitHub for setting up and submitting modules. Git is a version control system for tracking changes you make to files. GitHub is a hosting service for distributing Git repositories. These tools are essential for collaborative coding projects and it’s important to your development as a data scientist that you learn how to use them.\nThat said, Git and GitHub have a difficult learning curve. In this course, we’re going to limit ourselves to using some basic features. In future courses or when you’re doing research in a lab, you’ll have opportunities to learn more advanced Git and GitHub workflows. For more information about how data scientists use Git and GitHub, I recommend reading Bryan (2018).\nIn brief, module setup has two steps and submission has three.\n\nCreate your own remote repo on GitHub from the module template repo.\nCreate your local repo by cloning your remote to your computer.\n\nNow your computer is set up for the module. Complete the activity according to the instructions on the course website. When you’re done, proceed to the following steps.\n\nCommit your changes in the local repo.\nPush your local commit to the remote repo.\nOpen an Issue on GitHub and tag the instructors.\n\n\n  \n  \n\n\n\n\n\n\n\nImportant\n\n\n\nThere’s a decent chance these instructions feel overwhelming. It’s true, there’s a lot to learn even to set up and submit your modules - certainly trickier than uploading a PDF to Canvas. I encourage you to stick with it! After you set up and submit a couple modules you’ll feel a lot more confident, and by the end of the quarter you’ll have gained valuable experience with an important data science tool."
  },
  {
    "objectID": "modules.html#module-setup",
    "href": "modules.html#module-setup",
    "title": "Module Setup and Submission",
    "section": "Module setup",
    "text": "Module setup\n\nStep 1: Create your remote\nNavigate to the template repo on GitHub. Click on Use this template &gt; Create a new repository.\n\nFill out the “Create a new repository” form. The only field you need to fill out is “Repository name”. Make it match the module repository name (e.g., prog101). Click on the green “Create repository” button. Once GitHub creates the repo, you should see a URL that looks like “github.com/[your username]/[module name]”.\n\n\nStep 2: Clone your local repo\nCopy your remote repo’s URL (A) then switch over to RStudio and create a new RStudio project (B). In the New Project Wizard, choose Version Control &gt; Git then paste your URL and choose the local directory where you want to keep your local repositories (C-E). After clicking Create Project, RStudio will relaunch; you should see the project name updated in the top right and the Files pane should show the files from the template repo (F).\n\nAt this point you’re ready to work on the module. You have a local Git repository on your machine that is connected to your remote repository on GitHub."
  },
  {
    "objectID": "modules.html#module-submission",
    "href": "modules.html#module-submission",
    "title": "Module Setup and Submission",
    "section": "Module submission",
    "text": "Module submission\nWe’ll use GitHub Desktop for steps 3 and 4. Make sure GitHub Desktop recognizes your repo.\n\n\nStep 3: Commit your changes\nAfter you complete the module it’s time to commit your changes. This updates your local repository. In GitHub Desktop, you should see a list of files with changes on the left and the line-by-line differences on the right. Fill in the commit message below and hit the blue Commit to main button.\n\n\n\nStep 4: Push your commits\nAfter committing, you should no longer see any changed files. Click the Push origin button (A). This updates your remote repo on GitHub, which you can see online (B).\n\n\n\nStep 5: Open an Issue\nClick the Issues tab on GitHub (in the browser) and create a new Issue. Mention me (@FlukeAndFeather) in the Issue, which will let me know you’ve submitted your module. If you’re submitting the in-class portion for your pair, mention them as well. Congrats! You’re done!"
  },
  {
    "objectID": "pair-programming.html",
    "href": "pair-programming.html",
    "title": "Pair Programming",
    "section": "",
    "text": "We’re using pair programming for the in-class parts of modules. As the name suggests, pair programming is when two programmers write code together. Research shows that pair programming leads to better quality code in less time, so it’s popular in some software development circles. More importantly for you, it’s also been demonstrated that pair programming is an excellent learning tool (Hanks et al. 2011). There are lots of reasons pair programming helps learning. For example:"
  },
  {
    "objectID": "pair-programming.html#pair-programming-in-practice",
    "href": "pair-programming.html#pair-programming-in-practice",
    "title": "Pair Programming",
    "section": "Pair programming in practice",
    "text": "Pair programming in practice\nHere’s how we’ll use pair programming this quarter. Keep in mind: this is only for the in-class portion. The pre-class preparation (videos, notes, exercises) should be done individually.\n\nChoose a partner\nEach week you’ll form a pair with another student. There will be a question about who you’re working with on the end-of-week survey.\nHere are some important things to consider in choosing a partner:\n\nFind someone interested in similar modules as you are - you’ll be working on the same tasks together.\nPair programming works best when both partners have relatively similar experience levels with programming. I emphasize relative because no two of you are exactly the same. Slight differences are to be expected! However, a situation where one partner has substantial experience and the other is brand new will probably not work as well.\nI strongly encourage you to change partners every week! That may not always be possible based on module interest and experience level. However, when you can work with someone new please take that opportunity. Your learning will benefit from interacting the diversity of perspectives and experiences in the class.\n\n\n\nStart programming\n\nPut one laptop away. You’re both going to be working at one keyboard in one repository.\nChoose roles. One partner will be the driver and the other will be the navigator.\n\nThe driver’s primary responsibility is to type - you’ll be the one at the keyboard and focused on the in-the-weeds tasks.\nThe navigator’s primary responsibility is to talk - you’ll be guiding the conversation and staying focused on the big picture as the driver types.\nPrimary is emphasized because the line between the roles is fuzzy. The driver should be thinking critically and considering the whole of the problem. The navigator should be watching what the driver types and helping to find typos and other errors.\n\nSwitch roles every 20 minutes.\n\n\n\nSubmit the module\nBecause you’re both working at the same laptop, your repositories won’t match. Both of you should still submit your repositories on GitHub because I want to see both of your pre-class notes and exercises. Whichever partner’s repository contains the in-class part of the module should mention their partner in the issue they open to submit the repo."
  },
  {
    "objectID": "pair-programming.html#suggestions-for-effective-pair-programming",
    "href": "pair-programming.html#suggestions-for-effective-pair-programming",
    "title": "Pair Programming",
    "section": "Suggestions for effective pair programming",
    "text": "Suggestions for effective pair programming\n\nHave each others’ backs. You’re in this together! The most important way to support each other is coming to class ready to participate. The pre-class preparation is important for making sure you and your partner are both ready to collaborate. Give it your full attention.\nBe patient. When you’re new to coding, describing your ideas is really challenging. It’s natural to get frustrated when your partner doesn’t understand what you’re trying to tell them or vice versa. Figuring out how to articulate your ideas is important for learning how to do data science!\nTake breaks. Learning any skill, particularly technical skills, is mentally taxing. Your brain will saturate well before the end of a 75 minute class. Remind each other to get up, walk around, grab a drink of water - anything to unplug and reconnect."
  },
  {
    "objectID": "tracks/prog/prog101.html",
    "href": "tracks/prog/prog101.html",
    "title": "PROG101: Intro to R and RStudio",
    "section": "",
    "text": "This is the first module of the Programming track. By the end of this module, you’ll learn how to:"
  },
  {
    "objectID": "tracks/prog/prog101.html#pre-class-preparation",
    "href": "tracks/prog/prog101.html#pre-class-preparation",
    "title": "PROG101: Intro to R and RStudio",
    "section": "Pre-class preparation",
    "text": "Pre-class preparation\nSet up the PROG101 module on your computer (see Module Setup and Submission). There you’ll find the guided notes and exercises to accompany these recorded lectures.\n\n Lectures\n\nIntroduction to R and RStudio\n\n\n\nExpressions and variables\n\n\n\nUsing functions\n\n\n\nBasic vectors\n\n\n\nWorking with multiple vectors"
  },
  {
    "objectID": "tracks/prog/prog101.html#in-class-activity",
    "href": "tracks/prog/prog101.html#in-class-activity",
    "title": "PROG101: Intro to R and RStudio",
    "section": "In-class activity",
    "text": "In-class activity\n\nExtreme temperatures in an Alaskan intertidal zone\nThe intertidal zone is where the marine and terrestrial biomes meet. Organisms in this habitat must be able to withstand saltwater immersion, air exposure, and the impact of crashing waves. Some intertidal species are particularly important to both human and ecological communities, including bivalve shellfish like oysters, clams, and mussels. Bivalves may experience direct negative impacts from rising ocean temperatures, but they may receive indirect positive impacts from declining predator populations. From 2014-2016, an extreme marine heatwave gripped the North Pacific, popularly called “The Blob”. Around the same time, in 2013-2014, an outbreak of sea star wasting disease decimated sea stars along the North American Pacific coast, dramatically reducing the populations of these important bivalve predators. These two events could potentially push Alaskan mussel populations in opposing directions, which raises the question: have bivalves been winners or losers in a changing climate? Traiger et al. investigated this question using long-term monitoring data collected around the Gulf of Alaska (Traiger et al. 2022). Key to their study was an analysis of extreme air temperature. In this activity, you will replicate that part of their methods. Follow the assignment submission guidelines when you’ve completed this activity.\n\n\n\n\n\n\nNote\n\n\n\nThe template repository for this module is available at MarineCS-100B/prog101.\n\n\n\n\nGuiding questions\nRead the abstract and sections 2-2.1 of the methods in Traiger et al., then answer the following questions.\n\nWhat does KEFJ stand for?\nHow was temperature monitored?\nWhat’s the difference between absolute temperature and temperature anomaly?\n\n\n\nBegin exploring\nThe temperature and associated data from KEFJ is available in the marinecs100b R package. Use ?kefj to open the help page for these data.\n\nHow many kefj_* vectors are there?\nHow long are they?\nWhat do they represent?\n\nNow it’s time to begin coding! I want you to figure out the most common sampling interval for the temperature readings. First, sketch a plan on a piece of paper. Which vectors will you need to use? How are they related to each other? What operators or functions will you need?\n\n\n\n\n\n\nTip\n\n\n\nThe function table() will help you out here.\n\n\nNow, fill in the blanks below to get the most common sampling interval. Add comments describing what each line of code does.\n\n???_datetime &lt;- kefj_datetime[kefj_site == ???]\n???_interval &lt;- ???_datetime[???:???] - ???_datetime[???:???]\nt???e(???)\n\n\n\n\n\n\n\nNote\n\n\n\nThis is your first time dealing with dates and times in R. It’s going to take you a while to get used to them and you’ll definitely pull some hair out along the way. “Why isn’t this simpler??” you’ll ask. I wish it could be! But unfortunately we humans treat time in super weird ways and it’s next to impossible to represent it simply. Read “UTC is enough for everyone …right?” by Zach Holman for a humorous (if crass) breakdown of how we got into such a tangled situation.\n\n\n\n\nProblem decomposition\nLook how big the kefj_* vectors are. That’s way too big to tackle all at once! It’s always a good idea to break big, intractable problems down into smaller, digestible components. Let’s begin by finding the hottest and coldest air temperature readings in the dataset. When and where did these extremes happen? Use plot_kefj() to visualize the temperature readings for the days containing those readings. Before you start filling in the blanks in the code below, first sketch your plan for answering these questions. Make sure to consider which vectors you’ll need and how they relate to each other! When you start filling in the code below, add comments to each line of code describing what it does.\n\n\n\n\n\n\nTip\n\n\n\nCheck out which.min() and which.max()\n\n\n\n\n\n\n\n\nImportant\n\n\n\nThis code chunk introduces two new things in R.\nas.POSIXct() is a function for creating vectors that R recognizes as dates and times. For example, to create a variable representing noon on January 1, 2025 you could write jan1_2025 &lt;- as.POSIXct(\"2025-01-1 12:00\"). The tz argument specifies the timezone. \"Etc/GMT+8\" is the timezone the kefj data were collected in.\n& represents “and”. It’s how you combine multiple conditions that have to be true. For example, let’s say I have four people of different ages represented by these vectors:\npeople &lt;- c(\"Alice\", \"Bob\", \"Carla\", \"Danielle\")\nages &lt;- c(19, 16, 22, 29)\nThen I can find which people are older than 20 and younger than 25 like this:\npeople[ages &gt; 20 & ages &lt; 25]\n\n\n\n# Plot the hottest day\n\nhottest_idx &lt;- ???(kefj_temperature)\nhottest_time &lt;- ???[hottest_idx]\n??? &lt;- kefj_site[???]\nhotday_start &lt;- as.POSIXct(\"???\", tz = \"Etc/GMT+8\")\nhotday_end &lt;- as.POSIXct(\"???\", tz = \"Etc/GMT+8\")\nhotday_idx &lt;- ??? == hottest_site &\n  ??? &gt;= hotday_start &\n  ??? &lt;= hotday_end\nhotday_datetime &lt;- ???[hotday_idx]\nhotday_temperature &lt;- ???\nhotday_exposure &lt;- ???\nplot_kefj(???, ???, ???)\n\n# Repeat for the coldest day\n\nExamine your visualizations. What patterns do you notice in time, temperature, and exposure? Do those patterns match your intuition, or do they differ?\nNow that you’ve visualized the extreme temperatures you’re ready to begin calculating extreme temperature exposure. Re-read section 2.1 of Traiger et al. How did they define extreme heat exposure? Translate their written description to code and calculate the extreme heat exposure for the hottest day. Compare your answer to the visualization you made. Does it look right to you? Repeat this process for extreme cold exposure on the coldest day.\n\n\nPutting it back together (optional)\nYou’ll see more about problem decomposition in PROG103. If you’d like a preview, try the following.\nLet’s go from analyzing a single day to a whole season. Re-read how Traiger et al. quantified extreme hot and cold air temperature exposures at the seasonal scale. Make a sketch of how you would do that for a single site and season.\nPick one site and one season. What were the extreme heat and cold exposure at that site in that season? Repeat for a different site and a different season.\nTraiger et al. also calculated water temperature anomalies. Consider how you could do that. Make a sketch showing which vectors you would need and how you would use them. Write code to get the temperature anomalies for one site in one season in one year."
  },
  {
    "objectID": "tracks/prog/prog101.html#recap-and-next-steps",
    "href": "tracks/prog/prog101.html#recap-and-next-steps",
    "title": "PROG101: Intro to R and RStudio",
    "section": "Recap and next steps",
    "text": "Recap and next steps\nIn this module you started using R to represent and manipulate data. That’s a critical skill for a marine data scientist!\nFuture modules in this track will build on what you’ve learned here.\n\nIn this module, you called built-in R functions like which.min() and table(). In PROG102 you’ll learn how to write your own functions to encapsulate tasks like calculating extreme temperature exposure.\nPROG103 will cover branches and loops. Recall how you had to copy-paste-edit code in this module to apply the same task to different inputs (e.g., extreme hot vs extreme cold, one site vs another). That’s a time-consuming and error-prone way of doing things. Branches and loops are the solution for making choices and repeating operations.\n\nFill out the PROG101 reflection to complete this module. Well done!"
  },
  {
    "objectID": "tracks/prog/prog102.html",
    "href": "tracks/prog/prog102.html",
    "title": "PROG102: Functions",
    "section": "",
    "text": "This is the second module of the Programming track. By the end of this module, you’ll learn how to:"
  },
  {
    "objectID": "tracks/prog/prog102.html#pre-class-preparation",
    "href": "tracks/prog/prog102.html#pre-class-preparation",
    "title": "PROG102: Functions",
    "section": "Pre-class preparation",
    "text": "Pre-class preparation\nSet up the PROG102 module on your computer (see Module Setup and Submission). There you’ll find the guided notes to accompany these recorded lectures.\n\n Lectures\n\nWriting your own functions in R\n\n\n\nHow functions execute\n\n\n\nDefault and named parameters"
  },
  {
    "objectID": "tracks/prog/prog102.html#in-class-activity",
    "href": "tracks/prog/prog102.html#in-class-activity",
    "title": "PROG102: Functions",
    "section": "In-class activity",
    "text": "In-class activity\nIn PROG101 you quantified the hours of exposure a mussel bed experienced to extreme heat or cold in a day. However, to change the site or date you’d have to copy-paste-edit the entire code. In this activity, you’ll parameterize the extreme heat/cold procedures in functions to make them more readable and reusable.\nThis activity has multiple problems for you to solve, labeled P1, P2, P3, and so on. You’ll find the same labels in prog102.R in your copy of the module.\n\nWriting a utility function\nUtility functions are short functions that encapsulate a common task with a useful name. You’re going to write one for converting text to datetime objects in the Alaskan timezone.\nReview your code from PROG101. How did you extract the temperature and exposure from the hottest day? Copy-paste the code into prog102.R (P1). Make a mental note of the line of code that creates a datetime object (which R calls POSIXct).\nRecall functions have five parts:\n\nThe function’s name\nThe keyword function\nParameters, enclosed in parentheses\nThe function’s body, enclosed in curly braces\nA return for the output\n\nFill in the blanks below to write the Alaskan datetime utility function (P2). Its input should be a text string representing a datetime (e.g., “2020-02-02 16:00”). The output should be a POSIXct object for that datetime in the Alaskan timezone. Make sure you choose names for the function and parameters that make it easy to read! Each set of ‘???’ corresponds to one of the five parts of a function.\n??? &lt;- ???(???) {\n  ???\n  return(???)\n}\nYou’ll use this utility function in the next section, where you’ll write functions for extracting temperatures, exposures, and datetimes.\n\n\nExtracting data\nFirst, we’ll visualize temperature and exposure for two different sites on two different dates by copy-paste-edit.\nMake a copy of your code from P1 and edit it to plot the temperature and exposure for “Aialik” on 2012-06-01 (P3).\nMake a copy of your code from P3 and edit it to plot the temperature and exposure for “Harris” on 2016-04-05 (P4).\nCompare your solutions for P3 and P4 - what variables changed (P5)? The variables that change values for different inputs are what you want to pick for your function’s parameters.\n\n\n\n\n\n\nNote\n\n\n\nWhen converting code to a function, the process of changing fixed variables into flexible parameters is called parameterization.\n\n\nYou’re going to convert this code into a function. Remember that functions should make our code easier to read, which means the function and parameters should have descriptive names. What you would pick for the temperature extraction function and parameters’ names (P6)?\n\n\n\n\n\n\nTip\n\n\n\nWhen parameterizing a function, you’re usually going from a specific case to a more general purpose tool. That’s the whole point of reusable functions! So your parameter names will often be more general versions of the variable names used in the specific case.\n\n\n\n\nWriting extraction functions\nUsing the function and parameter names you picked, write a function (with all five parts!) that extracts the temperature for a given site and date. This is where you’ll use the utility function you wrote above. Fill in the blanks in the code below to write your temperature extraction function (P7).\n??? &lt;- ???(???, ???, ???) {\n  ??? &lt;- your_utility_function_name_here(???)\n  ??? &lt;- your_utility_function_name_here(???)\n  ???\n  return(???)\n}\nNow you’ll do the same for extracting exposure and datetimes. Make a copy of your solution to P7, and edit it to create exposure and datetime extraction functions (P8). As always, remember to choose helpful function names!\nTake a screenshot of the code for your temperature extraction function and annotate the screenshot (e.g. in Powerpoint or Keynote) to label the five parts of your function. Export your annotated version as a JPEG called “annotated_function.jpg” and add it to your copy of the module repository (P9).\nNow let’s test your functions. Extract the temperature, exposure, and datetime for site Nuka_Pass on July 1, 2018 and visualize them (P10). It may help to review as.POSIXct() and plot_kefj() from PROG101. Save a copy of the plot as “nuka_pass_2018-07-01.png” in this repo (P11). There’s an option to export a plot as an image from the Plots pane (see screenshot below).\n\nBy writing the three extraction functions, you’ve encapsulated the logic for extracting data. Compare the code you wrote to create the plot in this module to the code you wrote in PROG101. Qualitatively, how do they compare? Which one is easier to read and why? (P12)"
  },
  {
    "objectID": "tracks/prog/prog102.html#recap-and-next-steps",
    "href": "tracks/prog/prog102.html#recap-and-next-steps",
    "title": "PROG102: Functions",
    "section": "Recap and next steps",
    "text": "Recap and next steps\nIn this module you learned how to make your code more readable and reusable by writing functions.\nPROG103 is a complementary module to this one. There you’ll learn how to write branches (deciding what to do based on a condition) and loops. So while here we were still focused on individual sites and dates, in PROG103 you’ll learn how to loop over multiple sites and dates.\nFill out the PROG102 reflection to complete this module. Well done!"
  },
  {
    "objectID": "tracks/comm/comm101.html",
    "href": "tracks/comm/comm101.html",
    "title": "COMM101: Data Visualization with ggplot",
    "section": "",
    "text": "Welcome the Communication track. By the end of this module, you’ll learn how to:"
  },
  {
    "objectID": "tracks/comm/comm101.html#pre-class-preparation",
    "href": "tracks/comm/comm101.html#pre-class-preparation",
    "title": "COMM101: Data Visualization with ggplot",
    "section": "Pre-class preparation",
    "text": "Pre-class preparation\nSet up the COMM101 module on your computer (see Module Setup and Submission). There you’ll find the guided notes and exercises to accompany these recorded lectures.\n\n Lectures\n\nWelcome to the grammar of graphics\n\n\n\nIntroducing ggplot\n\n\n\nCustomization with scales and themes"
  },
  {
    "objectID": "tracks/comm/comm101.html#in-class-activity",
    "href": "tracks/comm/comm101.html#in-class-activity",
    "title": "COMM101: Data Visualization with ggplot",
    "section": "In-class activity",
    "text": "In-class activity\nWe introduced the the World Ocean Atlas (WOA) in INFO101 to examine worldwide seawater temperatures. The WOA contains a lot of oceanographic data, not just temperature. In this module, we’ll use the WOA and ggplot to visualize global sea surface salinity patterns.\n\nDistributions of continuous variables\nRecall our options for visualizing the distribution of continuous variables.\nP1 What type of visualization is appropriate for a single continuous variable?\nP2 What type of visualization is appropriate for a continuous variable across categorical variables?\nNow we’ll use these visualization types to look at the distribution of sea surface salinity. In the course companion package, you’ll find a data frame called woa_sal containing sea surface salinity data from the WOA.\n\n\n\n\n\n\nTip\n\n\n\nYou’re going to be saving several figures in this exercise. ggplot includes a function ggsave() that automates exporting ggplot figures to files. I encourage you to explore the help page to see how it works and the options available.\n\n\nP3 Use ggplot to visualize the distribution of sea surface salinity. Save your figure as “comm101p3.png”.\nP4 Use ggplot to visualize the distribution of sea surface salinity by ocean basin. Save your figure as “comm101p4.png”.\nP5 Interpret your figures from P3 and P4. What patterns do you notice?\nP6 Critique your figures from P3 and P4. What changes would highlight the patterns you interpreted in P5? You don’t need to write code for these changes, just describe them verbally.\n\n\nRelationships between continuous variables\nIn the previous section you visualized salinity at global and regional scales. Now we’re going to dig deeper into fine-scale patterns.\n\n\n\n\n\n\nNote\n\n\n\nDon’t be fooled by the brevity of the following question - this one may be tricky! Think carefully about the components of ggplot you learned about in the pre-class videos and exercises. What geometries and aesthetics are relevant here?\n\n\nP7 Visualize the relationship between salinity and latitude by ocean basin.\nP8 Edit your figure from P7 to improve its interpretability in at least one of the following categories: visually differentiating the oceans, appropriateness of the labels, or use of negative space. Save this figure as “comm101p8.png”."
  },
  {
    "objectID": "tracks/comm/comm101.html#recap-and-wrap-up",
    "href": "tracks/comm/comm101.html#recap-and-wrap-up",
    "title": "COMM101: Data Visualization with ggplot",
    "section": "Recap and wrap up",
    "text": "Recap and wrap up\nIn this module you learned how to make figures using ggplot. ggplot is one of the most popular tools for making scientific figures out there. It features in scientific journals, newspapers, and other sources. You’ll be using it a lot in your scientific career for exploring data and visually interpreting analyses!\nOnce you’ve completed the pre-class exercises and in-class activity, submit this module on GitHub."
  },
  {
    "objectID": "course-setup.html",
    "href": "course-setup.html",
    "title": "Course Setup Instructions",
    "section": "",
    "text": "This document will guide you to set up your computer for this course."
  },
  {
    "objectID": "course-setup.html#r-and-rstudio",
    "href": "course-setup.html#r-and-rstudio",
    "title": "Course Setup Instructions",
    "section": "R and RStudio",
    "text": "R and RStudio\nR is the programming language we’ll be using and RStudio is the interactive development environment we’ll use for writing and running code.\nGo to the RStudio installation page and install R first, then RStudio1.\nInstall the course companion package. Open RStudio and run the following commands in the Console pane:\ninstall.packages(\"remotes\")\nremotes::install_github(\"MarineCS-100B/marinecs100b\")"
  },
  {
    "objectID": "course-setup.html#git-and-github",
    "href": "course-setup.html#git-and-github",
    "title": "Course Setup Instructions",
    "section": "Git and GitHub",
    "text": "Git and GitHub\nGit is a version control system for keeping track of files and GitHub is an online hosting service for Git repositories. They’re important tools for data scientists and you’ll use them for submitting modules this quarter.\n\nGit on Windows\nInstall Git for Windows.\n\n\nGit on Mac\nInstall the Xcode Command Line Tools (which include Git). Open Terminal and run this command:\nxcode-select --install\n\n\nGitHub account\nWhile Git is installing, go to GitHub and create an account. Then install GitHub Desktop."
  },
  {
    "objectID": "course-setup.html#footnotes",
    "href": "course-setup.html#footnotes",
    "title": "Course Setup Instructions",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nIf you’re on a Mac, make sure you drag the application to your Application folder and eject the DMG. Don’t run RStudio directly from the DMG. Raise your hand if you have questions about this part!↩︎"
  },
  {
    "objectID": "tracks/info/info101.html",
    "href": "tracks/info/info101.html",
    "title": "INFO101: Tabular Data",
    "section": "",
    "text": "This is the first module of the Informatics track. By the end of this module, you’ll learn how to:"
  },
  {
    "objectID": "tracks/info/info101.html#pre-class-preparation",
    "href": "tracks/info/info101.html#pre-class-preparation",
    "title": "INFO101: Tabular Data",
    "section": "Pre-class preparation",
    "text": "Pre-class preparation\nSet up the INFO101 module on your computer (see Module Setup and Submission). There you’ll find the guided notes and exercises to accompany these recorded lectures.\n\n Lectures\n\nWhat makes data tidy?\n\n\n\nCreating data frames in R\n\n\n\nIndexing into rows and columns"
  },
  {
    "objectID": "tracks/info/info101.html#in-class-activity",
    "href": "tracks/info/info101.html#in-class-activity",
    "title": "INFO101: Tabular Data",
    "section": "In-class activity",
    "text": "In-class activity\nThe World Ocean Atlas (WOA) is a very important dataset in marine science. It is the easiest way to access data from the World Ocean Database (WOD), which is the most comprehensive collection of physical and biogeochemical oceanographic data ever assembled. The WOD is so valuable because it has been extensively reviewed and standardized, combining over 250 years of measurements in one place. Whereas the WOD is highly detailed, the WOA is a higher-level summary of this amazing dataset. The WOA is what we will be using today.\nBy the end of this module, you’ll make a figure similar to the one below. This figures shows the relationship between temperature and depth in the ocean about 500 miles west of here. Your figure won’t be as clean yet, but you’ll learn how to do that in COMM101!\n\n\nQuestionable organization choices\nYes, the WOA is an incredible resource. However, you will soon discover that it does not adhere to the tidy data principles you learned in the pre-class videos. This makes the dataset quite challenging to work with in R! Nothing gives you an appreciation for tidy data quite like struggling with weird data.\nFirst, download the latest version of the WOA (available here on Drive) and put it in your info101 directory.\nP1 Call the function dir() at the console. This lists the files in your project’s directory. Do you see woa.csv in the list? (If you don’t, move it to the right place before proceeding.)\nLet’s look at the contents of woa.csv in a spreadsheet viewer. You can use Excel if you have it on your computer or follow this link to view it in Google Sheets. Critique the organization of this spreadsheet according to the characteristics of tidy data. Recall, those are:\n\nMake it a rectangle\nDon’t confuse the computer\nConsistent names and formats\n\nP2 Critique the organization of woa.csv according to the characteristics of tidy data.\n\n\nImporting data\nNow we’re going to import the WOA into R. By the end of this section we will have a data frame with columns for latitude, longitude, and the many depth bins. Which is to say, you’re importing the wide-format version of the WOA, which is how this dataset is distributed.\nP3 Call read.csv() on woa.csv. What error message do you get? What do you think that means?\n\n\n\n\n\n\nTip\n\n\n\nIt may help to look at the contents of woa.csv in a spreadsheet viewer again.\n\n\nLet’s fix that error! Check the help page for read.csv() and look at the available parameters for read.table(). These parameters also apply to read.csv(). Which parameter do you think can help us avoid the problem in P3?\nP4 Re-write the call to read.csv() to avoid the error in P3.\nNow we have a data frame with the WOA data. Call View() on your data frame to see the data in RStudio’s viewer. You’ll notice we still have two issues.\n\nThe column names are very messy.\nThe depth variable is spread across 102 columns!\n\nWe’ll fix the first issue in this activity. The solution to the second issue (i.e., switching from wide to long format) is a technique called pivoting, which is outside the scope of this module. In a later section I will provide you with the pivoted, long-format version of the WOA in the course package.\n\n\nFix the column names\nWe need a character vector with clean column names to replace the messy ones. The first two columns are latitude and longitude, the next 102 columns are the different depths. First, we’re going to make a numeric vector of the different depth values. From there, we’ll create a character vector with clean column names.\nP5 Fill in the blanks below to create a vector of the depth values.\n\n\n\n\n\n\nTip\n\n\n\nseq() creates a sequence of values. Can you figure out how it works from context? Alternatively, check out the help page for details.\n\n\ndepths &lt;- c(\n  seq(0, 100, by = 5),\n  seq(???, ???, by = 25),\n  seq(???, ???, by = ???),\n  seq(???)\n)\nP6 Create a vector called woa_colnames with clean names for all 104 columns. Make them the column names of your WOA data frame.\n\n\n\n\n\n\nTip\n\n\n\npaste0() is a useful command for making column names (and other character vectors) from numeric vectors.\n\n\n\n\nAnalyzing wide-format data\nTo show why long format is considered tidier than wide format, we’re going to try summarizing the wide-format version of the WOA. Then you’ll do the same with the long-format version and compare the differences.\n\nSummary statistics (wide-format)\nTry to use indexing and summary statistic functions to answer the following question. This won’t be straightforward! The function mean() doesn’t work across columns in a data frame. You’ll have to get creative to figure out a solution. But in PROG101-PROG103 you learned the skills you need to accomplish it.\nP7 What is the mean water temperature globally in the twilight zone (200-1000m depth)?\n\n\n\n\n\n\nNote\n\n\n\nBy globally I mean across all locations, so no filtering by latitude or longitude necessary.\n\n\n\n\n\nAnalyzing long-format data\nAt this point you’ve imported a gnarly CSV file and tried analyzing it in wide-format. Not easy, is it? In this final section, you’ll get a taste of how long-format data frames make data analysis and visualization easier.\nA long-format version of the WOA is availabile in the course companion package, marinecs100b, under the name woa_long. Explore it on your own (e.g., using the help page or View()) to get a feel for it, then proceed to the following sections.\n\nSummary statistics (long-format)\nThis will be the same question as before, but with the long-format data instead of the wide-format.\nP8 Using woa_long, find the mean water temperature globally in the twilight zone.\nP9 Compare and contrast your solutions to P8 and P9.\n\n\nWhat’s the temperature of the Mariana Trench?\nThe Mariana Trench is located 11°21′N, 142°12′E. You’re going to filter woa_long to the nearest location and make a figure of the temperature profile with depth. This will end up looking similar to the “Temperature depth profile 500 miles west of Santa Barbara” figure from the beginning of this activity.\nThis is the first time you’re using ggplot directly, which is the most popular tool for making figures in R. You’ll learn more about how it works in COMM101.\nP10 Create a variable called mariana_temps. Filter woa_long to the rows in the location nearest to the coordinates listed above.\nThe sample code provided below will make a temperature-depth profile of the Mariana Trench using the variable you created in P10. Run it to create a figure.\n# ggplot is a tool for making figures, you'll learn its details in COMM101\nggplot(mariana_temps, aes(temp_c, depth_m)) +\n  geom_path() +\n  scale_y_reverse()\nP11 Interpret your temperature-depth profile. What’s the temperature at the surface? How about in the deepest parts? Over what depth range does temperature change the most?"
  },
  {
    "objectID": "tracks/info/info101.html#recap-and-next-steps",
    "href": "tracks/info/info101.html#recap-and-next-steps",
    "title": "INFO101: Tabular Data",
    "section": "Recap and next steps",
    "text": "Recap and next steps\nYou learned a lot in this module!\n\nWhat makes data tidy?\nHow to create, import, and index into data frames\nA taste of analyzing and visualizing data\n\nYou also debugged data import errors for the first time. Talk to any marine scientists working with data - that’s definitely a skill they wish they had learned earlier!\nFill out the INFO101 reflection to complete this module."
  },
  {
    "objectID": "tracks/prog/prog103.html",
    "href": "tracks/prog/prog103.html",
    "title": "PROG103: Branches and Loops",
    "section": "",
    "text": "This is the third module of the Programming track. By the end of this module, you’ll learn how to:"
  },
  {
    "objectID": "tracks/prog/prog103.html#pre-class-preparation",
    "href": "tracks/prog/prog103.html#pre-class-preparation",
    "title": "PROG103: Branches and Loops",
    "section": "Pre-class preparation",
    "text": "Pre-class preparation\nSet up the PROG103module on your computer (see Module Setup and Submission). There you’ll find the guided notes and exercises to accompany these recorded lectures.\n\n Lectures\n\nConditions in R\n\n\n\nMaking choices with if, else, and else if\n\n\n\nRepeating yourself with vectorized functions\n\n\n\nRepeating yourself with for loops"
  },
  {
    "objectID": "tracks/prog/prog103.html#in-class-activity",
    "href": "tracks/prog/prog103.html#in-class-activity",
    "title": "PROG103: Branches and Loops",
    "section": "In-class activity",
    "text": "In-class activity\nIn PROG102 you wrote functions to extract temperatures, exposures, and time from the kefj dataset. Here, you’ll use loops and if-then statements to calculate extreme hot and cold exposure across sites and season.\nTraiger et al. (2022) defined extreme hot and cold exposure as air temperatures ≥25°C and ≤-4°C, respectively. The goal here is to calculate the hours of extreme hot and cold exposure on average per day in each site and season. For example, on average, how many hours of extreme heat did mussels in Aialik experience in summer?\n\nReview: write a function\nYour first task is to review what you learned in PROG102 by writing a function to encapsulate a procedure.\nP1 Describe succinctly what the following code does. This should be a high-level, one-sentence description, not a line-by-line breakdown.\n\n\n\n\n\n\nTip\n\n\n\nRemember the most common sampling interval from PROG101! Each temperature record represents 30 minutes of time.\n\n\n\nsite &lt;- \"Nuka_Pass\"\nseason &lt;- \"Late winter\"\nn_cold &lt;- sum(kefj_site == site &\n                kefj_season == season &\n                kefj_temperature &lt;= -4 &\n                kefj_exposure == \"air\")\nn_total &lt;- sum(kefj_site == site &\n                 kefj_season == season)\nhours_cold &lt;- n_cold * 30 / 60\ndays_total &lt;- n_total * 30 / 60 / 24\nhours_cold_per_day &lt;- hours_cold / days_total\nhours_cold_per_day\n\nP2 Let’s turn that code chunk into a function. What would you call that function? How many parameters should it take and what would you call them?\nP3 Write a function to encapsulate the code chunk above. Check that it contains all five parts of a function.\n\n\nMake an extreme choice\nThe code chunk above focuses on extreme cold exposure, but we would like to use a similar procedure for extreme heat exposure. In order, here’s what we’ll do.\n\nUse an if else statement to create a logical vector indicating whether temperatures are extreme.\nIncorporate the new logical vector into our old code chunk to make it more flexible.\nAdd a parameter to your function so it can handle extreme heat or cold.\n\nP4 Fill in the code below to create a logical vector indicating extreme temperatures.\n\nextreme_type &lt;- \"cold\"\nif (??? == \"???\") {\n  is_extreme &lt;- kefj_temperature ??? ???\n} ??? {\n  ???\n}\n\nP5 Copy-paste the code from P1 and edit it to incorporate the is_extreme vector into the extreme temperature exposure procedure.\nP6 Copy-paste the function you wrote in P3 and edit it to add a parameter that lets you switch between extreme heat and cold exposure.\n\n\n\n\n\n\nImportant\n\n\n\nMake sure that when you edit the function you choose readable names for the function, its parameters, and any variables you define in the body!\n\n\n\n\nSeason to taste\nIn the previous section, you used if then to make choices. Now, you’re going to use for loops to repeat an operation over multiple inputs. In order, you’ll:\n\nIdentify the unique seasons to loop over\nCalculate extreme heat and cold exposure in each season (for a given site)\nAdd a nested loop to iterate over the unique sites, as well\n\nWhen you’re done, you’ll use the results of your loops to find the mildest season in Alaska.\nP7 What seasons are in the kefj dataset? What function would you use to identify them?\nP8 Fill in the blanks below to make a for loop that prints the extreme hot and cold exposure across seasons at site Aialik.\n\nseasons &lt;- ???\nfor (??? in ???) {\n  heat_exposure &lt;- ???(???, ???, \"hot\")\n  cold_exposure &lt;- ???\n  print(paste(\"Aialik\", ???, heat_exposure, cold_exposure))\n}\n\nP9 Copy-paste your answer to P8 and add a nested for loop to iterate across sites as well as seasons.\nP10 Examine your results from P9. You should find two outputs where both extreme heat and cold exposure were 0. What season were they in?"
  },
  {
    "objectID": "tracks/prog/prog103.html#recap-and-next-steps",
    "href": "tracks/prog/prog103.html#recap-and-next-steps",
    "title": "PROG103: Branches and Loops",
    "section": "Recap and next steps",
    "text": "Recap and next steps\nIn this module you learned how to make make decisions and repeat yourself - key skills for writing complex code!\nThis completes the essential coding skills you need for this class. Options for next steps are:\nINFO101 - learn how data are organized in tables.\nPRST101 - learn to summarize data and prepare for probability and statistics.\nCOMM101 - learn to visualize data and begin making publication-quality figures (but do INFO101 first).\nFill out the PROG103 reflection to complete this module. Well done!"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Intro to Marine Data Science",
    "section": "",
    "text": "Data science merges computer science and statistics with a particular field of study. In our case, that particular field of study is marine science. You and your classmates will explore examples from marine research to learn data science skills and tools.\n\n\n\nComputational thinking and writing code (Programming)\nDescribing and simulating data (Probability and statistics)\nOrganizing, sharing, and finding data (Informatics)\nCommunicating your results and data science workflow (Communication)\n\n\n\n\nIntro to Marine Data Science is a self-directed, mastery-oriented class. As your instructor, I want you to take ownership for your learning and focus on mastering the skills that excite you. That’s hard to do in traditional class formats because you’re all entering this class with diverse experiences, interests, and goals.\nThis class has an experimental format. There are more lessons available to you on this course website than I expect you to complete in one quarter. Your task is to choose the lessons that match your interests and goals, and work through them with a partner. Each lesson has readings and/or recorded lectures, and exercises for you to complete before class. In class, you’ll apply the skills from that lesson to real-world questions, like:\n\nWhere are the world’s oceans warming the fastest?\nAre deep-sea fish and invertebrates important prey for marine predators?\nHow can we fill in the at-sea data collection gaps caused by Covid?"
  },
  {
    "objectID": "index.html#course-description",
    "href": "index.html#course-description",
    "title": "Intro to Marine Data Science",
    "section": "",
    "text": "Data science merges computer science and statistics with a particular field of study. In our case, that particular field of study is marine science. You and your classmates will explore examples from marine research to learn data science skills and tools.\n\n\n\nComputational thinking and writing code (Programming)\nDescribing and simulating data (Probability and statistics)\nOrganizing, sharing, and finding data (Informatics)\nCommunicating your results and data science workflow (Communication)\n\n\n\n\nIntro to Marine Data Science is a self-directed, mastery-oriented class. As your instructor, I want you to take ownership for your learning and focus on mastering the skills that excite you. That’s hard to do in traditional class formats because you’re all entering this class with diverse experiences, interests, and goals.\nThis class has an experimental format. There are more lessons available to you on this course website than I expect you to complete in one quarter. Your task is to choose the lessons that match your interests and goals, and work through them with a partner. Each lesson has readings and/or recorded lectures, and exercises for you to complete before class. In class, you’ll apply the skills from that lesson to real-world questions, like:\n\nWhere are the world’s oceans warming the fastest?\nAre deep-sea fish and invertebrates important prey for marine predators?\nHow can we fill in the at-sea data collection gaps caused by Covid?"
  },
  {
    "objectID": "index.html#teaching-team",
    "href": "index.html#teaching-team",
    "title": "Intro to Marine Data Science",
    "section": "Teaching Team",
    "text": "Teaching Team\n\n\n\nInstructor\n\n\n\n\n\n\n\n\n\n\n\nMax Czapanskiy\nEmail: maxczap@ucsb.edu\n\n\n\n\nLearning Assistant\n\n\n\n\n\n\n\n\n\n\n\nHayden Vega\nEmail: haydenvega@umail.ucsb.edu"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\n1 + 1\n\n[1] 2"
  }
]